{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBlCij3C8_mM",
        "outputId": "41a23fdf-1e17-4add-dc05-207fb22f1c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /kaggle/input/flowers-recognition\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alxmamaev/flowers-recognition\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuQ2mvlQ9FaW",
        "outputId": "a529eb29-7a03-4349-aedc-2d95338eeaa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images directory: /kaggle/input/flowers-recognition/flowers/flower_images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "images_directory = os.path.join(\"/kaggle/input/flowers-recognition/flowers\", \"flower_images\")\n",
        "print(\"Images directory:\", images_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_nuyrIPu9dy-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "train_aug = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nCa_UZkT9m4y"
      },
      "outputs": [],
      "source": [
        "val_aug = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V0vhMRJG9nzZ"
      },
      "outputs": [],
      "source": [
        "target_size = (224, 224)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXdy8SIe9p39",
        "outputId": "c4b5840a-62d9-4cb4-8a68-981ed51171c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3457 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = train_aug.flow_from_directory(\n",
        "    \"/kaggle/input/flowers-recognition/flowers\",\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHFOSMKi9sma",
        "outputId": "3b7b63bf-e055-4fd8-c7a0-6e0fa93b25e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 860 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "val_data = val_aug.flow_from_directory(\n",
        "    \"/kaggle/input/flowers-recognition/flowers\",\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot3E9ErS-Ga9",
        "outputId": "c468b842-8991-40f4-eaf3-622b1462cc64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "resnet_base = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "resnet_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p7sXwDG--PKS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "moOoF89_-TM9"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a0aqXOOh-Vt7"
      },
      "outputs": [],
      "source": [
        "model.add(resnet_base)\n",
        "model.add(layers.GlobalAveragePooling2D())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q_EVbrsj-Wr8"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Dense(256))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KJYDGdgU-YQ8"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Dense(128))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SKcvzC6k-a1T"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Dense(64))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d92txxSB-dHb"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mVgat-Q8_PuQ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2aZctl3oAJPW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35BXZBAU_TFU",
        "outputId": "a92ec2b3-4fa0-496b-9ca7-0b66e2f42857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 646ms/step - accuracy: 0.6477 - loss: 0.9242 - val_accuracy: 0.8581 - val_loss: 0.4113\n",
            "Epoch 2/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 437ms/step - accuracy: 0.8499 - loss: 0.4474 - val_accuracy: 0.8907 - val_loss: 0.2977\n",
            "Epoch 3/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 440ms/step - accuracy: 0.8729 - loss: 0.3851 - val_accuracy: 0.8930 - val_loss: 0.2907\n",
            "Epoch 4/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 437ms/step - accuracy: 0.8729 - loss: 0.3531 - val_accuracy: 0.9128 - val_loss: 0.2851\n",
            "Epoch 5/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 440ms/step - accuracy: 0.9020 - loss: 0.2909 - val_accuracy: 0.8988 - val_loss: 0.2683\n",
            "Epoch 6/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 433ms/step - accuracy: 0.8971 - loss: 0.3013 - val_accuracy: 0.8977 - val_loss: 0.2852\n",
            "Epoch 7/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 439ms/step - accuracy: 0.9232 - loss: 0.2435 - val_accuracy: 0.9000 - val_loss: 0.2726\n",
            "Epoch 8/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 447ms/step - accuracy: 0.9217 - loss: 0.2193 - val_accuracy: 0.9093 - val_loss: 0.2769\n",
            "Epoch 9/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 439ms/step - accuracy: 0.9125 - loss: 0.2526 - val_accuracy: 0.9198 - val_loss: 0.2730\n",
            "Epoch 10/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 449ms/step - accuracy: 0.9368 - loss: 0.1735 - val_accuracy: 0.9151 - val_loss: 0.2766\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c50e0223e50>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_data, validation_data=val_data, epochs=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
